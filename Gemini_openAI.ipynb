{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0y7x-8zVxk-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# ----------------------------\n",
        "# Logging (production-friendly)\n",
        "# ----------------------------\n",
        "logging.basicConfig(\n",
        "    level=os.getenv(\"LOG_LEVEL\", \"INFO\"),\n",
        "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
        ")\n",
        "log = logging.getLogger(\"gemini-client\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "@dataclass(frozen=True)\n",
        "class Settings:\n",
        "    # Gemini OpenAI-compatible endpoint (AI Studio / Generative Language API)\n",
        "    base_url: str = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "    api_key: str = os.getenv(\"GEMINI_API_KEY\", \"\")\n",
        "    model: str = os.getenv(\"MODEL\", \"gemini-2.5-flash\")\n",
        "\n",
        "    # Reliability controls\n",
        "    timeout_seconds: int = int(os.getenv(\"TIMEOUT_SECONDS\", \"30\"))\n",
        "    max_retries: int = int(os.getenv(\"MAX_RETRIES\", \"3\"))\n",
        "    retry_backoff_seconds: float = float(os.getenv(\"RETRY_BACKOFF_SECONDS\", \"1.5\"))\n",
        "\n",
        "\n",
        "def build_client(settings: Settings) -> OpenAI:\n",
        "    if not settings.api_key:\n",
        "        raise ValueError(\n",
        "            \"Missing GEMINI_API_KEY. Set it as an environment variable.\"\n",
        "        )\n",
        "\n",
        "    # OpenAI SDK client pointed to Gemini\n",
        "    return OpenAI(\n",
        "        api_key=settings.api_key,\n",
        "        base_url=settings.base_url,\n",
        "        timeout=settings.timeout_seconds,\n",
        "    )\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Core wrapper (single place to call the model)\n",
        "# ----------------------------\n",
        "class LLMService:\n",
        "    def __init__(self, settings: Settings):\n",
        "        self.settings = settings\n",
        "        self.client = build_client(settings)\n",
        "\n",
        "    def chat(self, user_text: str, system_text: str = \"You are a helpful assistant.\") -> str:\n",
        "        last_error: Optional[Exception] = None\n",
        "\n",
        "        for attempt in range(1, self.settings.max_retries + 1):\n",
        "            try:\n",
        "                resp = self.client.chat.completions.create(\n",
        "                    model=self.settings.model,\n",
        "                    messages=[\n",
        "                        {\"role\": \"system\", \"content\": system_text},\n",
        "                        {\"role\": \"user\", \"content\": user_text},\n",
        "                    ],\n",
        "                )\n",
        "                return resp.choices[0].message.content or \"\"\n",
        "\n",
        "            except Exception as e:\n",
        "                last_error = e\n",
        "                log.warning(\"LLM call failed (attempt %s/%s): %s\",\n",
        "                            attempt, self.settings.max_retries, repr(e))\n",
        "                if attempt < self.settings.max_retries:\n",
        "                    sleep_for = self.settings.retry_backoff_seconds * attempt\n",
        "                    time.sleep(sleep_for)\n",
        "\n",
        "        # If all retries fail, raise a clean error\n",
        "        raise RuntimeError(f\"LLM call failed after retries: {last_error!r}\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Example usage\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    settings = Settings()\n",
        "    llm = LLMService(settings)\n",
        "\n",
        "    prompt = \"Explain to me how AI works in simple terms.\"\n",
        "    answer = llm.chat(prompt)\n",
        "\n",
        "    print(\"\\n--- MODEL ANSWER ---\\n\")\n",
        "    print(answer)\n"
      ]
    }
  ]
}